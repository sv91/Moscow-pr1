function beta = logisticRegression(y,tX,alpha)
% Initial values
    [~,N] = size(tX);
    beta = zeros(N,1);
    maxIters = 1000;
    lastBeta = beta;
    convergence= 0.00001;

    for k = 1:maxIters
    	g = computeGradient(y, tX,beta);
        H = computeHessian(tx, beta);
        beta = beta - alpha * inv(H) * g;
        if abs(lastBeta - beta)< beta*convergence 
            break % If the difference between two step is too small, we stop
        end
    end
end

function g = computeGradient(y,tX,beta)
    size(y)
    e = logFun(tX*beta) - y;    %compute error
    g = tX'*e;   
end

function H = computeHessian(tx, beta)
    [N,~] = size(tX);
    S = zeros(N);
    for i = 0:N
        S(i,i) = logFun(tx(i)'*beta)*(1-logFun(tx(i)'*beta));
    end
    H = tX'* S * tX;
end

function o = logFun(x)
    o2 = exp(x)/(1+exp(x));
    o = o2(~,0);
end